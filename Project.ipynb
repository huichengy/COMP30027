{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP30027 Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import BernoulliRBM, MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"./Data/train_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "train_top10 = pd.read_csv(\"./Data/train_top10.csv\", header=None, na_values='?', keep_default_na=False)\n",
    "\n",
    "dev_raw = pd.read_csv(\"./Data/dev_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "dev_top10 = pd.read_csv(\"./Data/dev_top10.csv\", header=None, na_values='?', keep_default_na=False)\n",
    "\n",
    "test_raw = pd.read_csv(\"./Data/test_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "test_top10 = pd.read_csv(\"./Data/test_top10.csv\", header=None, na_values='?', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Initial Test)\n",
    "### k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf1 = KNeighborsClassifier(int(math.sqrt(train_top10.size)), \"distance\", n_jobs=-1)\n",
    "# cf1.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# cf1.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf1.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf2 = GaussianNB()\n",
    "# cf2.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf2.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Decision Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf3 = RandomForestClassifier()\n",
    "# cf3.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf3.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf4 = MLPClassifier()\n",
    "# cf4.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf4.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier with Decision Tree _(default)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf5 = AdaBoostClassifier(n_estimators=100)\n",
    "# cf5.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf5.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Combine UID)\n",
    "\n",
    "First combine all UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laitingsheng\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:4290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[col] = expressions.where(mask, this, that)\n"
     ]
    }
   ],
   "source": [
    "def unique(top10, raw):\n",
    "    b = top10.copy()\n",
    "    b[0] = raw[0]\n",
    "    a = b.drop_duplicates(0)\n",
    "    a.update(b.iloc[:, :31].groupby(0).mean())\n",
    "    return a\n",
    "\n",
    "a = unique(train_top10, train_raw)\n",
    "b = unique(dev_top10, dev_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.588194\n",
      "True     0.411806\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf1 = GradientBoostingClassifier(n_estimators=1000)\n",
    "cf1.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf1.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.57712\n",
      "True     0.42288\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf2 = MLPClassifier()\n",
    "cf2.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf2.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier with Decision Tree _(default)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.588083\n",
      "True     0.411917\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf3 = AdaBoostClassifier(n_estimators=100)\n",
    "cf3.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf3.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembled _(Stacking)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.588194\n",
      "True     0.411806\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(a.values[:, 31])\n",
    "\n",
    "na = pd.DataFrame()\n",
    "na[0] = a[0]\n",
    "na[1] = enc.transform(cf1.predict(a.values[:, 1:31]))\n",
    "na[2] = enc.transform(cf2.predict(a.values[:, 1:31]))\n",
    "na[3] = enc.transform(cf3.predict(a.values[:, 1:31]))\n",
    "na[4] = a[31]\n",
    "nb = pd.DataFrame()\n",
    "nb[0] = b[0]\n",
    "nb[1] = enc.transform(cf1.predict(b.values[:, 1:31]))\n",
    "nb[2] = enc.transform(cf2.predict(b.values[:, 1:31]))\n",
    "nb[3] = enc.transform(cf3.predict(b.values[:, 1:31]))\n",
    "nb[4] = b[31]\n",
    "\n",
    "ecf = AdaBoostClassifier(n_estimators=100)\n",
    "ecf.fit(na.values[:, 1:4], na.values[:, 4])\n",
    "\n",
    "mapping = pd.Series(ecf.predict(nb.values[:, 1:4]), nb.iloc[:, 0])\n",
    "t = dev_top10.copy()\n",
    "t[0] = dev_raw[0]\n",
    "\n",
    "p = t[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "t.update(p)\n",
    "re = (t[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf = MLPClassifier()\n",
    "# cf.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "# mapping = pd.Series(cf.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "# predict_test_top10 = test_top10.copy()\n",
    "# predict_test_top10[0] = test_raw[0]\n",
    "\n",
    "# p = predict_test_top10[[0, 31]]\n",
    "# def rc(row):\n",
    "#     row[31] = mapping[row[0]]\n",
    "#     return row\n",
    "# p = p.apply(rc, 1, raw=True)\n",
    "# p[0] = test_top10[0]\n",
    "# predict_test_top10.update(p)\n",
    "# re = predict_test_top10[[0, 31]]\n",
    "# re.columns = [\"Id\", \"Prediction\"]\n",
    "# re.to_csv(\"./Data/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
