{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP30027 Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neural_network import BernoulliRBM, MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"./Data/train_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "train_top10 = pd.read_csv(\"./Data/train_top10.csv\", header=None, na_values='?', keep_default_na=False)\n",
    "\n",
    "dev_raw = pd.read_csv(\"./Data/dev_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "dev_top10 = pd.read_csv(\"./Data/dev_top10.csv\", header=None, na_values='?', keep_default_na=False)\n",
    "\n",
    "test_raw = pd.read_csv(\"./Data/test_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "test_top10 = pd.read_csv(\"./Data/test_top10.csv\", header=None, na_values='?', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Initial Test)\n",
    "### k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf1 = KNeighborsClassifier(int(math.sqrt(train_top10.size)), \"distance\", n_jobs=-1)\n",
    "# cf1.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# cf1.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf1.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf2 = GaussianNB()\n",
    "# cf2.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf2.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Decision Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf3 = RandomForestClassifier()\n",
    "# cf3.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf3.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf4 = MLPClassifier()\n",
    "# cf4.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf4.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier with Decision Tree _(default)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf5 = AdaBoostClassifier(n_estimators=100)\n",
    "# cf5.fit(train_top10[:, 1:31], train_top10[:, 31])\n",
    "# t = cf5.predict(dev_top10[:, 1:31]) == dev_top10[:, 31]\n",
    "# t = np.bincount(t)\n",
    "# s = t[1] / (t[0] + t[1])\n",
    "# print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by Age Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     0.521949\n",
      "False    0.478051\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "gd = train_top10.copy()\n",
    "gd[0] = train_raw[0]\n",
    "ga = gd.iloc[:, :31].groupby(0).sum()\n",
    "ga = ga.div(ga.sum(axis=1), 0).fillna(0)\n",
    "gad = gd.drop_duplicates(0)[[0, 31]]\n",
    "tcf = MultinomialNB()\n",
    "tcf.fit(ga.values, gad[31].values)\n",
    "\n",
    "d = dev_top10.copy()\n",
    "d[0] = dev_raw[0]\n",
    "a = d.iloc[:, :31].groupby(0).sum()\n",
    "a = a.div(a.sum(axis=1), 0).fillna(0)\n",
    "ad = d.drop_duplicates(0)[[0, 31]]\n",
    "mapping = pd.Series(tcf.predict(a.values), ad[0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Combine UID)\n",
    "\n",
    "First combine all UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:4290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[col] = expressions.where(mask, this, that)\n"
     ]
    }
   ],
   "source": [
    "def unique(top10, raw):\n",
    "    b = top10.copy()\n",
    "    b[0] = raw[0]\n",
    "    a = b.drop_duplicates(0)\n",
    "    a.update(b.iloc[:, :31].groupby(0).mean())\n",
    "    return a\n",
    "\n",
    "a = unique(train_top10, train_raw)\n",
    "b = unique(dev_top10, dev_raw)\n",
    "c = unique(test_top10, test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.58601\n",
      "True     0.41399\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf1 = GradientBoostingClassifier(n_estimators=1000)\n",
    "cf1.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf1.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.578068\n",
      "True     0.421932\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf2 = MLPClassifier()\n",
    "cf2.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf2.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier with Decision Tree _(default)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.588083\n",
      "True     0.411917\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf3 = AdaBoostClassifier(n_estimators=100)\n",
    "cf3.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf3.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.573458\n",
      "True     0.426542\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf4 = LogisticRegression()\n",
    "cf4.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf4.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembled _(Stacking)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.58698\n",
      "True     0.41302\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(a.values[:, 31])\n",
    "\n",
    "na = pd.DataFrame()\n",
    "na[0] = a[0]\n",
    "na[1] = enc.transform(cf1.predict(a.values[:, 1:31]))\n",
    "na[2] = enc.transform(cf2.predict(a.values[:, 1:31]))\n",
    "na[3] = enc.transform(cf3.predict(a.values[:, 1:31]))\n",
    "na[4] = a[31]\n",
    "nb = pd.DataFrame()\n",
    "nb[0] = b[0]\n",
    "nb[1] = enc.transform(cf1.predict(b.values[:, 1:31]))\n",
    "nb[2] = enc.transform(cf2.predict(b.values[:, 1:31]))\n",
    "nb[3] = enc.transform(cf3.predict(b.values[:, 1:31]))\n",
    "nb[4] = b[31]\n",
    "nc = pd.DataFrame()\n",
    "nc[0] = c[0]\n",
    "nc[1] = enc.transform(cf1.predict(c.values[:, 1:31]))\n",
    "nc[2] = enc.transform(cf2.predict(c.values[:, 1:31]))\n",
    "nc[3] = enc.transform(cf3.predict(c.values[:, 1:31]))\n",
    "nc[4] = c[31]\n",
    "\n",
    "ecf = AdaBoostClassifier(n_estimators=100)\n",
    "ecf.fit(na.values[:, 1:4], na.values[:, 4])\n",
    "\n",
    "mapping = pd.Series(ecf.predict(nb.values[:, 1:4]), nb.iloc[:, 0])\n",
    "t = dev_top10.copy()\n",
    "t[0] = dev_raw[0]\n",
    "\n",
    "p = t[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "t.update(p)\n",
    "re = (t[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)\n",
    "\n",
    "mapping = pd.Series(ecf.predict(nc.values[:, 1:4]), nc.iloc[:, 0])\n",
    "t = test_top10.copy()\n",
    "t[0] = test_raw[0]\n",
    "\n",
    "p = t[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = test_top10[0]\n",
    "t.update(p)\n",
    "re = t[[0, 31]]\n",
    "re.columns = [\"Id\", \"Prediction\"]\n",
    "re.to_csv(\"./Data/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(sublinear_tf=True)\n",
    "\n",
    "ut = train_raw.drop_duplicates(0)\n",
    "t = train_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "tfid = tv.fit_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 381595)\n"
     ]
    }
   ],
   "source": [
    "print(tfid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=100, tol=None)\n",
    "rcf.fit(tfid, ut[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941899441340782"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rcf.predict(tfid) == ut[2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = dev_raw[[0, 2, 6]].drop_duplicates(0)\n",
    "d = dev_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "dfid = tv.transform(d)\n",
    "\n",
    "groups = {\n",
    "    14: \"14-16\", 15: \"14-16\", 16: \"14-16\",\n",
    "    24: \"24-26\", 25: \"24-26\", 26: \"24-26\",\n",
    "    34: \"34-36\", 35: \"34-36\", 36: \"34-36\",\n",
    "    44: \"44-46\", 45: \"44-46\", 46: \"44-46\"\n",
    "}\n",
    "\n",
    "p = pd.Series(rcf.predict(dfid), ud[0]).apply(lambda x: groups.get(x, float(\"nan\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dev_raw[[0, 2]]\n",
    "def rc(row):\n",
    "    row[2] = p[row[0]]\n",
    "    return row\n",
    "d = d.apply(rc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6221212388599665\n"
     ]
    }
   ],
   "source": [
    "print((d[2] == dev_top10[31]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = test_raw[[0, 2, 6]].drop_duplicates(0)\n",
    "d = test_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "dfid = tv.transform(d)\n",
    "\n",
    "p = pd.Series(rcf.predict(dfid), ud[0]).apply(lambda x: groups.get(x, float(\"nan\")))\n",
    "\n",
    "d = test_raw[[0, 2]]\n",
    "def rc(row):\n",
    "    row[2] = p[row[0]]\n",
    "    return row\n",
    "d = d.apply(rc, 1)\n",
    "d[0] = test_top10[0]\n",
    "d.columns = [\"Id\", \"Prediction\"]\n",
    "d.to_csv(\"./Data/temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
