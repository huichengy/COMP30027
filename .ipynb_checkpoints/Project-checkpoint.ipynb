{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP30027 Machine Learning Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"./Data/train_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "train_top10 = pd.read_csv(\"./Data/train_top10.csv\", header=None, na_values='?', keep_default_na=False)\n",
    "\n",
    "dev_raw = pd.read_csv(\"./Data/dev_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "dev_top10 = pd.read_csv(\"./Data/dev_top10.csv\", header=None, na_values='?', keep_default_na=False)\n",
    "\n",
    "test_raw = pd.read_csv(\"./Data/test_raw.csv\", header=None, na_values='?', keep_default_na=False, usecols=[0, 2, 6])\n",
    "test_top10 = pd.read_csv(\"./Data/test_top10.csv\", header=None, na_values='?', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Initial Test)\n",
    "### k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.43027000794141\n"
     ]
    }
   ],
   "source": [
    "cf1 = KNeighborsClassifier(int(math.sqrt(train_top10.size)), \"distance\", n_jobs=-1)\n",
    "cf1.fit(train_top10.values[:, 1:31], train_top10.values[:, 31])\n",
    "t = cf1.predict(dev_top10.values[:, 1:31]) == dev_top10.values[:, 31]\n",
    "t = np.bincount(t)\n",
    "s = t[1] / (t[0] + t[1])\n",
    "print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.41601958881143564\n"
     ]
    }
   ],
   "source": [
    "cf2 = GaussianNB()\n",
    "cf2.fit(train_top10.values[:, 1:31], train_top10.values[:, 31])\n",
    "t = cf2.predict(dev_top10.values[:, 1:31]) == dev_top10.values[:, 31]\n",
    "t = np.bincount(t)\n",
    "s = t[1] / (t[0] + t[1])\n",
    "print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Decision Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.43384364246007234\n"
     ]
    }
   ],
   "source": [
    "cf3 = RandomForestClassifier()\n",
    "cf3.fit(train_top10.values[:, 1:31], train_top10.values[:, 31])\n",
    "t = cf3.predict(dev_top10.values[:, 1:31]) == dev_top10.values[:, 31]\n",
    "t = np.bincount(t)\n",
    "s = t[1] / (t[0] + t[1])\n",
    "print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.434924556604606\n"
     ]
    }
   ],
   "source": [
    "cf4 = MLPClassifier()\n",
    "cf4.fit(train_top10.values[:, 1:31], train_top10.values[:, 31])\n",
    "t = cf4.predict(dev_top10.values[:, 1:31]) == dev_top10.values[:, 31]\n",
    "t = np.bincount(t)\n",
    "s = t[1] / (t[0] + t[1])\n",
    "print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boost Classifier with Decision Tree _(default)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.433667166681373\n"
     ]
    }
   ],
   "source": [
    "cf5 = AdaBoostClassifier(n_estimators=100)\n",
    "cf5.fit(train_top10.values[:, 1:31], train_top10.values[:, 31])\n",
    "t = cf5.predict(dev_top10.values[:, 1:31]) == dev_top10.values[:, 31]\n",
    "t = np.bincount(t)\n",
    "s = t[1] / (t[0] + t[1])\n",
    "print(f\"score: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Combine UID)\n",
    "\n",
    "First combine all UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laitingsheng\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:4290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[col] = expressions.where(mask, this, that)\n"
     ]
    }
   ],
   "source": [
    "def unique(top10, raw):\n",
    "    b = top10.copy()\n",
    "    b[0] = raw[0]\n",
    "    a = b.drop_duplicates(0)\n",
    "    a.update(b.iloc[:, :31].groupby(0).mean())\n",
    "    return a\n",
    "\n",
    "a = unique(train_top10, train_raw)\n",
    "b = unique(dev_top10, dev_raw)\n",
    "c = unique(test_top10, test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.581267\n",
      "True     0.418733\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf1 = KNeighborsClassifier(int(math.sqrt(train_top10.size)), \"distance\", n_jobs=-1)\n",
    "cf1.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf1.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.58601\n",
      "True     0.41399\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf2 = GradientBoostingClassifier(n_estimators=1000)\n",
    "cf2.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf2.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.578267\n",
      "True     0.421733\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf3 = MLPClassifier()\n",
    "cf3.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf3.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boost Classifier with Decision Tree _(default)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.588083\n",
      "True     0.411917\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf4 = AdaBoostClassifier(n_estimators=100)\n",
    "cf4.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf4.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.573458\n",
      "True     0.426542\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cf5 = LogisticRegression()\n",
    "cf5.fit(a.values[:, 1:31], a.values[:, 31])\n",
    "\n",
    "mapping = pd.Series(cf5.predict(b.values[:, 1:31]), b.iloc[:, 0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembled _(Stacking)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.581267\n",
      "True     0.418733\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(a.values[:, 31])\n",
    "\n",
    "na = pd.DataFrame()\n",
    "na[0] = a[0]\n",
    "na[1] = enc.transform(cf1.predict(a.values[:, 1:31]))\n",
    "na[2] = enc.transform(cf3.predict(a.values[:, 1:31]))\n",
    "na[3] = enc.transform(cf5.predict(a.values[:, 1:31]))\n",
    "na[4] = a[31]\n",
    "nb = pd.DataFrame()\n",
    "nb[0] = b[0]\n",
    "nb[1] = enc.transform(cf1.predict(b.values[:, 1:31]))\n",
    "nb[2] = enc.transform(cf3.predict(b.values[:, 1:31]))\n",
    "nb[3] = enc.transform(cf5.predict(b.values[:, 1:31]))\n",
    "nb[4] = b[31]\n",
    "nc = pd.DataFrame()\n",
    "nc[0] = c[0]\n",
    "nc[1] = enc.transform(cf1.predict(c.values[:, 1:31]))\n",
    "nc[2] = enc.transform(cf3.predict(c.values[:, 1:31]))\n",
    "nc[3] = enc.transform(cf5.predict(c.values[:, 1:31]))\n",
    "nc[4] = c[31]\n",
    "\n",
    "ecf = AdaBoostClassifier(n_estimators=100)\n",
    "ecf.fit(na.values[:, 1:4], na.values[:, 4])\n",
    "\n",
    "mapping = pd.Series(ecf.predict(nb.values[:, 1:4]), nb.iloc[:, 0])\n",
    "t = dev_top10.copy()\n",
    "t[0] = dev_raw[0]\n",
    "\n",
    "p = t[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "t.update(p)\n",
    "re = (t[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)\n",
    "\n",
    "mapping = pd.Series(ecf.predict(nc.values[:, 1:4]), nc.iloc[:, 0])\n",
    "t = test_top10.copy()\n",
    "t[0] = test_raw[0]\n",
    "\n",
    "p = t[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = test_top10[0]\n",
    "t.update(p)\n",
    "re = t[[0, 31]]\n",
    "re.columns = [\"Id\", \"Prediction\"]\n",
    "re.to_csv(\"./Data/temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by Age Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     0.521949\n",
      "False    0.478051\n",
      "Name: 31, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "gd = train_top10.copy()\n",
    "gd[0] = train_raw[0]\n",
    "ga = gd.iloc[:, :31].groupby(0).sum()\n",
    "ga = ga.div(ga.sum(axis=1), 0).fillna(0)\n",
    "gad = gd.drop_duplicates(0)[[0, 31]]\n",
    "tcf = MultinomialNB()\n",
    "tcf.fit(ga.values, gad[31].values)\n",
    "\n",
    "d = dev_top10.copy()\n",
    "d[0] = dev_raw[0]\n",
    "a = d.iloc[:, :31].groupby(0).sum()\n",
    "a = a.div(a.sum(axis=1), 0).fillna(0)\n",
    "ad = d.drop_duplicates(0)[[0, 31]]\n",
    "mapping = pd.Series(tcf.predict(a.values), ad[0])\n",
    "predict_dev_top10 = dev_top10.copy()\n",
    "predict_dev_top10[0] = dev_raw[0]\n",
    "\n",
    "p = predict_dev_top10[[0, 31]]\n",
    "def rc(row):\n",
    "    row[31] = mapping[row[0]]\n",
    "    return row\n",
    "p = p.apply(rc, 1, raw=True)\n",
    "p[0] = dev_top10[0]\n",
    "predict_dev_top10.update(p)\n",
    "re = (predict_dev_top10[31] == dev_top10[31]).value_counts(True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw (TF-IDF Vectoriser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(sublinear_tf=True)\n",
    "rcf = SGDClassifier(random_state=41, max_iter=1000, tol=None, n_jobs=-1)\n",
    "\n",
    "groups = {\n",
    "    14: \"14-16\", 15: \"14-16\", 16: \"14-16\",\n",
    "    24: \"24-26\", 25: \"24-26\", 26: \"24-26\",\n",
    "    34: \"34-36\", 35: \"34-36\", 36: \"34-36\",\n",
    "    44: \"44-46\", 45: \"44-46\", 46: \"44-46\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7144800390716857\n",
      "0.48246271949174974\n"
     ]
    }
   ],
   "source": [
    "tfid = tv.fit_transform(train_raw[6].values)\n",
    "\n",
    "rcf.fit(tfid, train_raw[2].apply(lambda x: groups.get(x, '?')).values)\n",
    "print((rcf.predict(tfid) == dev_raw[31]).mean())\n",
    "\n",
    "dfid = tv.transform(dev_raw[6].values)\n",
    "print((pd.Series(rcf.predict(dfid), dev_top10.index).apply(lambda x: groups.get(x, '?')) == dev_top10[31]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = tv.fit_transform(train_raw[6].values)\n",
    "\n",
    "rcf.fit(tfid, train_raw[2].apply(.values)\n",
    "print((rcf.predict(tfid) == train_raw[2]).mean())\n",
    "\n",
    "dfid = tv.transform(dev_raw[6].values)\n",
    "print((pd.Series(rcf.predict(dfid), dev_top10.index).apply(lambda x: groups.get(x, '?')) == dev_top10[31]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943016759776536\n",
      "0.6191211506220771\n"
     ]
    }
   ],
   "source": [
    "ut = train_raw.drop_duplicates(0)\n",
    "t = train_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "tfid = tv.fit_transform(t)\n",
    "\n",
    "rcf.fit(tfid, ut[2])\n",
    "print((rcf.predict(tfid) == ut[2]).mean())\n",
    "\n",
    "ud = dev_raw[[0, 2, 6]].drop_duplicates(0)\n",
    "d = dev_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "dfid = tv.transform(d)\n",
    "\n",
    "p = pd.Series(rcf.predict(dfid), ud[0]).apply(lambda x: groups.get(x, '?'))\n",
    "\n",
    "d = dev_raw[[0, 2]]\n",
    "def rc(row):\n",
    "    row[2] = p[row[0]]\n",
    "    return row\n",
    "d = d.apply(rc, 1)\n",
    "print((d[2] == dev_top10[31]).mean())\n",
    "ud = test_raw[[0, 2, 6]].drop_duplicates(0)\n",
    "d = test_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "dfid = tv.transform(d)\n",
    "\n",
    "p = pd.Series(rcf.predict(dfid), ud[0]).apply(lambda x: groups.get(x, '?'))\n",
    "\n",
    "d = test_raw[[0, 2]]\n",
    "def rc(row):\n",
    "    row[2] = p[row[0]]\n",
    "    return row\n",
    "d = d.apply(rc, 1)\n",
    "d[0] = test_top10[0]\n",
    "d.columns = [\"Id\", \"Prediction\"]\n",
    "d.to_csv(\"./Data/temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laitingsheng\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981340782122905\n",
      "0.6412688608488485\n"
     ]
    }
   ],
   "source": [
    "ut = train_raw.drop_duplicates(0)\n",
    "t = train_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "tfid = tv.fit_transform(t)\n",
    "\n",
    "ut[2] = ut[2].apply(lambda x: groups.get(x, '?'))\n",
    "rcf.fit(tfid, ut[2])\n",
    "print((rcf.predict(tfid) == ut[2]).mean())\n",
    "\n",
    "ud = dev_raw[[0, 2, 6]].drop_duplicates(0)\n",
    "d = dev_raw.groupby(0)[6].apply(lambda x: ' '.join(x))\n",
    "dfid = tv.transform(d)\n",
    "\n",
    "p = pd.Series(rcf.predict(dfid), ud[0])\n",
    "\n",
    "d = dev_raw[[0, 2]]\n",
    "def rc(row):\n",
    "    row[2] = p[row[0]]\n",
    "    return row\n",
    "d = d.apply(rc, 1)\n",
    "print((d[2] == dev_top10[31]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
